{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5lKKqtgh87q"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "\n",
        "# Parameter\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state= 33)\n",
        "i = 1\n",
        "total_akurasi_svm = 0\n",
        "total_akurasi_logreg = 0\n",
        "\n",
        "score_accuracy_svm = []\n",
        "score_accuracy_logreg = []\n",
        "score_precision_svm = []\n",
        "score_precision_logreg = []\n",
        "score_recall_svm = []\n",
        "score_recall_logreg = []\n",
        "score_f1_svm = []\n",
        "score_f1_logreg = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    print(\"Fold ke: \", i)\n",
        "    print(\"Train Index: \", train_index)\n",
        "    print(\"Test Index: \", test_index)\n",
        "    X_train = X[train_index]\n",
        "    X_test = X[test_index]\n",
        "    y_train = y[train_index]\n",
        "    y_test = y[test_index]\n",
        "\n",
        "    # Menggunakan TF-IDF\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    X_train = tfidf_vectorizer.fit_transform(X_train)\n",
        "    X_test = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "    # Model 1: SVM linear\n",
        "    model_svm = SVC(kernel='linear')\n",
        "    model_svm.fit(X_train, y_train)\n",
        "    y_pred_svm = model_svm.predict(X_test)\n",
        "    akurasi_svm = accuracy_score(y_test, y_pred_svm)\n",
        "    total_akurasi_svm += akurasi_svm\n",
        "\n",
        "    # precision, recall, F1-score SVM\n",
        "    precision_svm = precision_score(y_test, y_pred_svm)\n",
        "    recall_svm = recall_score(y_test, y_pred_svm)\n",
        "    f1_svm = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "    print(f\"Nilai Akurasi SVM {i}   : %.2f%%\" % (akurasi_svm * 100.0))\n",
        "    print(f\"Nilai Precision SVM {i} : %.2f%%\" % (precision_svm * 100.0))\n",
        "    print(f\"Nilai Recall SVM {i}    : %.2f%%\" % (recall_svm * 100.0))\n",
        "    print(f\"Nilai F1 SVM {i}        : %.2f%%\" % (f1_svm * 100.0))\n",
        "\n",
        "    print('Confusion Matrix (SVM):')\n",
        "    print(confusion_matrix(y_test, y_pred_svm), \"\\n\")\n",
        "\n",
        "    score_accuracy_svm.append(akurasi_svm * 100)\n",
        "    score_precision_svm.append(precision_svm * 100)\n",
        "    score_recall_svm.append(recall_svm * 100)\n",
        "    score_f1_svm.append(f1_svm * 100)\n",
        "\n",
        "    # Model 2: Logistic Regression\n",
        "    model_logreg = LogisticRegression()\n",
        "    model_logreg.fit(X_train, y_train)\n",
        "    y_pred_logreg = model_logreg.predict(X_test)\n",
        "    akurasi_logreg = accuracy_score(y_test, y_pred_logreg)\n",
        "    total_akurasi_logreg += akurasi_logreg\n",
        "\n",
        "    # precision, recall, F1-score Logistic Regression\n",
        "    precision_logreg = precision_score(y_test, y_pred_logreg)\n",
        "    recall_logreg = recall_score(y_test, y_pred_logreg)\n",
        "    f1_logreg = f1_score(y_test, y_pred_logreg)\n",
        "\n",
        "    print(f\"Nilai Akurasi LogReg {i}   : %.2f%%\" % (akurasi_logreg * 100.0))\n",
        "    print(f\"Nilai Precision LogReg {i} : %.2f%%\" % (precision_logreg * 100.0))\n",
        "    print(f\"Nilai Recall LogReg {i}    : %.2f%%\" % (recall_logreg * 100.0))\n",
        "    print(f\"Nilai F1 LogReg {i}        : %.2f%%\" % (f1_logreg * 100.0))\n",
        "\n",
        "    print('Confusion Matrix (LogReg):')\n",
        "    print(confusion_matrix(y_test, y_pred_logreg), \"\\n\")\n",
        "\n",
        "    score_accuracy_logreg.append(akurasi_logreg * 100)\n",
        "    score_precision_logreg.append(precision_logreg * 100)\n",
        "    score_recall_logreg.append(recall_logreg * 100)\n",
        "    score_f1_logreg.append(f1_logreg * 100)\n",
        "\n",
        "    # Increment fold\n",
        "    i += 1\n",
        "\n",
        "print(\"Akurasi Rata2 SVM: %.2f%%\" % (np.mean(score_accuracy_svm)))\n",
        "print(\"Akurasi Rata2 LogReg: %.2f%%\" % (np.mean(score_accuracy_logreg)), \"\\n\")\n",
        "print(\"Precision Rata2 SVM: %.2f%%\" % (np.mean(score_precision_svm)))\n",
        "print(\"Precision Rata2 LogReg: %.2f%%\" % (np.mean(score_precision_logreg)), \"\\n\")\n",
        "print(\"Recall Rata2 SVM: %.2f%%\" % (np.mean(score_recall_svm)))\n",
        "print(\"Recall Rata2 LogReg: %.2f%%\" % (np.mean(score_recall_logreg)), \"\\n\")\n",
        "print(\"F1 Rata2 SVM: %.2f%%\" % (np.mean(score_f1_svm)))\n",
        "print(\"F1 Rata2 LogReg: %.2f%%\" % (np.mean(score_f1_logreg)), \"\\n\")"
      ]
    }
  ]
}